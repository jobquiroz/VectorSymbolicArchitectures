{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring storing capabilities of Hyperdimensional Binary Vectors\n",
    "\n",
    "In this notebook there's a simple implementation of a Hyperdimensional Computing system. We use the Semantic Pointer Architecture (SPA) using binary vectors for encoding semantic feature norms as proposed by McRae's dataset. \n",
    "This program explores the storing and retrieval capabilities of Hyperdimensional vectors, by asking the question: How many concepts can be stored and then retrieved within a binary vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Header of the program\n",
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Global variables\n",
    "N = 10000      # Vectors' lenght\n",
    "#ones = int(N*0.6931)  #Amount of ones in vector. With this value 50% of elements in vectors are ones (N = 1000 -> 0.694)\n",
    "#N = 1000; ones = int(N*0.694)\n",
    "ones = int(N*0.694)\n",
    "\n",
    "Dict = {}     # Dictionary -> Symbols catalog\n",
    "thr = 0.45 * N  #Similarity threshold\n",
    "\n",
    "Memory = [[],[],[]]  # The entire associative memory. First row is symbols (HDvector object), second row is label (string),\n",
    "                     # and third row is its definition, if it exists (HDvector object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General functions for vectors and auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General functions for vectors\n",
    "def SparseBitString(n):\n",
    "    \"\"\"This function generates a random binary vector\n",
    "    n: length of vector\n",
    "    BitString: Binary vector\"\"\"\n",
    "    # Generates 'ones' different random numbers ranging from 0 to n-1\n",
    "    Address = np.random.randint(0, n-1, ones)\n",
    "    # Initialize binary vector\n",
    "    BitString = np.zeros(n, dtype = np.int8)\n",
    "    # Set to 1 the address generated\n",
    "    BitString[Address] = 1\n",
    "    return BitString\n",
    "\n",
    "def ADD(*arg):\n",
    "    \" General function for vectors addition, it assumes that the argument is an object HDvector\"\n",
    "    if len(arg) == 1 and type(arg[0]) is list:\n",
    "        arg = arg[0]\n",
    "    len_0 = arg[0].lenght\n",
    "    Sum = np.zeros(len_0) # Initialize sum vector\n",
    "    n = len(arg) # Number of vectors to add\n",
    "    for vec in arg:\n",
    "        assert vec.lenght == len_0  # Are all dimensions equal??\n",
    "        Sum = Sum + vec.vec         # 'normal' sum\n",
    "    Sum = Sum / n                   # Average\n",
    "    Sum[Sum > 0.5] = 1              #Thresholding\n",
    "    Sum[Sum == 0.5] = SparseBitString(len_0)[Sum == 0.5]  # If average equal to 0.5 -> select a random value (0 or 1)\n",
    "    return HDvector(Sum.astype(np.int8))\n",
    "\n",
    "def flat_list (L):\n",
    "    \"Recursive function that flats a list of lists (at any level)\"\n",
    "    if L == []:\n",
    "        return L\n",
    "    if type(L[0]) is list:\n",
    "        return flat_list(L[0]) + flat_list(L[1:])\n",
    "    return L[:1] + flat_list(L[1:])\n",
    "\n",
    "def flat_list_1l (L):\n",
    "    \"Flattens a list one level only\"\n",
    "    R = []\n",
    "    for l in L:\n",
    "        R.extend(l)\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A class for Hyperdimensional vectors\n",
    "\n",
    "This class includes the initialization, getters and setters functions as well as Arithmetical operations for managing HD vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperdimensional vectors class\n",
    "class HDvector (object):\n",
    "    # We can initialize our vector with its content (array) or its length (content random)\n",
    "    def __init__ (self, vec_or_len, label = None, pointer = None):\n",
    "        global Memory   # We use global variable\n",
    "        \n",
    "        if type(vec_or_len) is int: # Initializing vector by lenght\n",
    "            self.lenght = vec_or_len\n",
    "            self.vec = SparseBitString(vec_or_len)\n",
    "            \n",
    "        elif type(vec_or_len) is np.ndarray:   # Initializing vector by content\n",
    "            self.lenght = len(vec_or_len)\n",
    "            self.vec = vec_or_len\n",
    "            \n",
    "        else:\n",
    "            raise TypeError(\"Input has to be integer (length) or numpy array\")\n",
    "        \n",
    "        # If a string label is given, the initialized vector is added in global catalogs\n",
    "        if label in Memory[1]:\n",
    "            raise NameError(\"Label '\" + str(label) + \"'is already in catalog!\")\n",
    "        elif label:\n",
    "            Memory[1].append(label)\n",
    "            Memory[2].append(pointer)\n",
    "            if len(Memory[0]) != 0:\n",
    "                Memory[0] = np.concatenate((Memory[0], self.vec.reshape((1,N))))\n",
    "            Dict[label] = self   # label is linked to vector -> (added to global dictionary)\n",
    "            \n",
    "        self.label = label       # assigning vector label\n",
    "        self.pointer = pointer   # assigning pointer (vector)\n",
    "        \n",
    "        # Index of this object in global Memory...\n",
    "        self.index = len(Memory[0]) - 1\n",
    "    \n",
    "    \n",
    "    # Getters\n",
    "    def getVec(self):   # it returns the array of the HD vector object\n",
    "        return self.vec\n",
    "    \n",
    "    \n",
    "    def getLabelID (self, num = N): # return label, it can be its assigned label or a list of the 'num' closest vectors labels\n",
    "        if self.label:  # if it has an assigned label\n",
    "            return [[self.label, 0]]\n",
    "        \n",
    "        else: #This vector hasn't a label. We find the 'num' most similar vectors in dictionary return a list of them\n",
    "            HamVec = np.array([self.dist_vec(x) for x in Memory[0]]) #Distance to all vectors in memory\n",
    "            # Indices where HamVec[i] < similarity threshold\n",
    "            Indices = np.where(HamVec < thr)[0]\n",
    "            # Cutting list to 'num'\n",
    "            Indices = Indices[:num]\n",
    "            # Result is a list of lists [label, distance]\n",
    "            L = [[Memory[1][i], HamVec[i]] for i in Indices]\n",
    "            return sorted(L, key = lambda r: r[1])\n",
    "                \n",
    "    def getLabelSP(self, num = N):   #get label of vector by searching in definitions...\n",
    "        # Collect indeces where there's an actual pointer vector...\n",
    "        Index = [i for i,x in enumerate(Memory[2]) if type(x) == np.ndarray]\n",
    "        HamVec = np.array([self.dist_vec(Memory[2][x]) for x in Index])\n",
    "        Indices = np.where(HamVec < thr)[0]  # Indices below similarity threshold\n",
    "        Indices = Indices[:num]\n",
    "        \n",
    "        #Result is a list of lsits [label,distance]\n",
    "        L = [[Memory[1][Index[i]], HamVec[i]] for i in Indices]\n",
    "        return sorted(L, key = lambda r: r[1])\n",
    "        \n",
    "    def getPointer(self):\n",
    "        return self.pointer\n",
    "    \n",
    "    # Setters\n",
    "    def setContent(self, in_array): #Set a new content\n",
    "        self.vec = in_array\n",
    "    def setPointer(self, other):    #Set a vector to point to\n",
    "        self.pointer = other\n",
    "        Memory[2][self.index] = other.getVec()  #setting new vector..\n",
    "    \n",
    "    # Distance\n",
    "    def dist(self, other):        #Measure distance between two object vectors\n",
    "        assert self.lenght == other.lenght    #Sanity check\n",
    "        return np.count_nonzero(self.vec != other.vec)\n",
    "    def dist_vec(self, vecc):      #Measure distance between an object vector and a numpy array (sometimes useful)\n",
    "        assert self.lenght == len(vecc)      #Sanity check\n",
    "        return np.count_nonzero(self.vec != vecc)\n",
    "    \n",
    "    # Arithmetic \n",
    "    def p(self, times):     #Pemutation aka rolling\n",
    "        return HDvector(np.roll(self.vec, times))\n",
    "    def ip(self, times):    #Inverse permutation aka inverse rolling\n",
    "        return HDvector(np.roll(self.vec, self.lenght - times))\n",
    "    def __add__(self, other): #Add\n",
    "        return ADD(self, other)\n",
    "    def __mul__(self, other):  #Multiplication\n",
    "        return HDvector( np.bitwise_xor(self.vec, other.vec))\n",
    "    def __pow__(self, other):  #Function that multiplies self's pointer by other's vector\n",
    "        if isinstance(self.getPointer(), HDvector):\n",
    "            return HDvector(np.bitwise_xor(self.getPointer().getVec(), other.vec))\n",
    "\n",
    "    # Other functions\n",
    "    def conc (self, other):  #Concatenate two vector objects arrays\n",
    "        return HDvector(np.concatenate((self.vec, other.vec)))\n",
    "    def __str__(self):\n",
    "        return str(self.vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory initialization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    \"Initialize vector 'null' and symbol matrix\"\n",
    "    global Dict, Memory\n",
    "    Dict = {}; Memory = [[],[],[]]; feature_vectors = []\n",
    "    thr = 0.45 * N  # Initial similarity threshold (later changed)\n",
    "    # Null vector \n",
    "    null = HDvector(N, 'null')  # Initialize by size and label\n",
    "    # Store vector in global array, this has to be done only once...\n",
    "    Memory[0] = np.array([null.getVec()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory functions (writing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SaveConcepts(Dic):\n",
    "    \"\"\"Given a definitions dictionary it stores in memory the entire set of concepts in the dictionary (including feature vectors)\"\"\"\n",
    "    keys = Dic.keys()\n",
    "    vals = Dic.values()\n",
    "    all_concepts = list(set(flat_list(vals) + keys))\n",
    "    # Process for storing list of concepts in memory\n",
    "    for concept in all_concepts:\n",
    "        HDvector(N,concept) #This creates an object and store it in memory\n",
    "\n",
    "def FeatureVectors(Dic):\n",
    "    global feature_vectors\n",
    "    featt = []\n",
    "    vals = Dic.values()\n",
    "    for l in vals:\n",
    "        for p in l:\n",
    "            featt.append(p[0])\n",
    "    feature_vectors = list(set(featt))\n",
    "            \n",
    "def CreateSemanticPointer (PairList):\n",
    "    \"Turns list as [[feat1,feat_val],[feat2,feat_val],[feat3,feat_val]] into vector feat1*feat_val + feat2*feat_val ...\"\n",
    "    vecs = []\n",
    "    for pair in PairList:\n",
    "        vecs.append(Dict[pair[0]] * Dict[pair[1]])\n",
    "    return ADD(vecs)\n",
    "        \n",
    "def SaveDefinitions(Dic):\n",
    "    \"\"\"Given the definitions dictionary, and having all its concepts previously stored in memory, this functions\n",
    "       creates a definition vector (semantic pointer) using HD operations and assign it as a pointer to an \n",
    "       object vector (ID vector).\"\"\"\n",
    "    global Dict #decía -> feature_vectors\n",
    "    # Going through all elements in dictionary\n",
    "    for key, value in Dic.iteritems():\n",
    "        Dict[key].setPointer(CreateSemanticPointer(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory functions (reading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RetrieveDef (HDvec):\n",
    "    \"This function extract all feat_values from a given vector and returns a list of its labels\"\n",
    "    R = []\n",
    "    for feat_vec in feature_vectors: #feature_vectors is a global variable...\n",
    "        feat_val = HDvec * Dict[feat_vec]\n",
    "        R.append(feat_val.getLabelID())\n",
    "    return R\n",
    "\n",
    "\n",
    "def DistanceOnevsAll (label):\n",
    "    \"This functions measure the average and max distance from HDvec to all other vectors in memory\"\n",
    "    D = []\n",
    "    for elem in Dict:\n",
    "        if elem != label:\n",
    "            D.append(Dict[label].dist(Dict[elem]))\n",
    "\n",
    "    return [round(sum(D) / float(len(D)),2), max(D), min(D)]\n",
    "\n",
    "def DistanceAllvsAll ():\n",
    "    R = []\n",
    "    for elem in Dict:\n",
    "        R.append(DistanceOnevsAll(elem))\n",
    "    Avg = [x[0] for x in R]\n",
    "    Max = [x[1] for x in R]\n",
    "    Min = [x[2] for x in R]\n",
    "    return [round(sum(Avg) / float(len(Avg)),2), max(Max),min(Min)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excel managing functions\n",
    "\n",
    "This functions reads an excel file called FEATS_brm from the McRae's dataset to translate feature names such as \"is_red\" into a python list like [is, red]. \n",
    "This is going to be used for encoding each concept into hyperdimensional vectors by means of arithmetical operations like concept = is * red + ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TranslateFeats(ListFeat):\n",
    "    \" It receives a list of features such as ['is_blue', 'is_rectangular'] and it returns the same list translated to pairs of feat_name and feat_value: [['color','blue'], ['shape','rectangular'] \"\n",
    "    # Dataframe for excel document\n",
    "    df = pd.read_excel('../McRaedataset/FEATS_brm.xlsx')\n",
    "    ListPairs = []\n",
    "    for feat in ListFeat:\n",
    "        # Row for feature...\n",
    "        row = df.loc[df['Feature'] == feat]       \n",
    "        # Look for values in vec_feat and vec_value\n",
    "        ListPairs.append([str(row['feat_name'].tolist()[0]), str(row['feat_value'].tolist()[0])])       \n",
    "    return ListPairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions dictionary\n",
    "\n",
    "Here we define a dictionary with the definition of a single concept (from McRae's dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dict_defs = {'apple': ['is_red','a_fruit','grows_on_trees','is_green','eaten_in_pies',\n",
    "                'is_crunchy','has_seeds','is_juicy','tastes_sweet','is_round',\n",
    "                'is_delicious','is_nutritious','is_yellow','has_a_core','has_skin',\n",
    "                'tastes_sour','used_for_cider','eg_-_granny_smith','is_worm_infested',\n",
    "                'used_for_cooking', 'worn_for_protection', 'made_of_cloth','has_strings',\n",
    "                'worn_for_covering_clothes', 'worn_in_kitchens', 'made_of_cotton',\n",
    "                'associated_with_angels', 'associated_with_babies', 'beh_-_eats_fish',\n",
    "                'beh_-_eats_nuts', 'is_wall_to_wall','is_warm','lives_by_the_ocean',\n",
    "                'lives_in_a_colony', 'made_by_oysters','made_from_dried_grapes',\n",
    "                'requires_a_license','requires_air','smells_bad', 'symbol_of_freedom',\n",
    "                'used_at_Easter','used_on_walls','used_with_tea_cups','worn_with_skirts',\n",
    "                'used_underwater','used_when_people_are_ill','used_in_alcoholic_drinks','used_in_autumn',\n",
    "                'is_attached_to_chains','is_attached_to_ropes','beh_-_climbs_trees','beh_-_clucks',\n",
    "                'eg_-_wood','eg_weeping','found_at_bus_stops','has_8_tentacles','has_a_back','has_a_bag',\n",
    "                'has_wings','herded_by_shepherds','hunted_by_people','worn_over_clothes','used_in_autumn',\n",
    "                'used_as_a_gift','owned_by_companies','lives_near_water','lives_on_lily_pads',\n",
    "                'becomes_a_butterfly','causes_bad_breath','causes_cancer']\n",
    "     }\n",
    "\n",
    "def format_dict (Dic, num_features):\n",
    "    # Format dictionary\n",
    "    for x in Dic:\n",
    "        Dict_defs[x] = TranslateFeats(Dict_defs[x][0:num_features])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average, Max and Min distance all vs all: [4998.6, 5174, 4818]\n",
      "\n",
      "Similarity Threshold: 4528\n",
      "\n",
      "Time elapsed:  0.0430002212524\n",
      "\n",
      "# of features in definition: 70\n",
      "\n",
      "Successfully retrieved features: 31.43 %\n",
      "\n",
      "Average distance (from retrieved vector to stored ID vector): 4448.59\n",
      "\n",
      "Max distance (but smaller than threshold): 4492\n"
     ]
    }
   ],
   "source": [
    "def Main():\n",
    "    # Initialization\n",
    "    init()\n",
    "    \n",
    "    #Giving format to dictionary -> change original feature names for list [feat_name, feat_value]\n",
    "    format_dict(Dict_defs, 70)\n",
    "    \n",
    "    # List of feature names\n",
    "    FeatureVectors(Dict_defs)\n",
    "    # Save each individual concept into memory\n",
    "    SaveConcepts(Dict_defs)\n",
    "    # Assign a semantic pointer to defined concepts\n",
    "    SaveDefinitions(Dict_defs)\n",
    "#    print 'Feature vectors:', feature_vectors,'\\n'\n",
    "    \n",
    "    # Measuring distance between all vectors...\n",
    "    DistList = DistanceAllvsAll()\n",
    "    print \"Average, Max and Min distance all vs all:\", DistList\n",
    "    # New similarity threshold\n",
    "    thr = int( 0.94 * DistList[2] )\n",
    "    print \"\\nSimilarity Threshold:\", thr\n",
    "    \n",
    "    \n",
    "    # Retrieving feature values from definition in memory\n",
    "    start = time.time()\n",
    "    Feat = RetrieveDef(Dict['apple'].getPointer())\n",
    "    print \"\\nTime elapsed: \", time.time() - start\n",
    "    \n",
    "    Feat = flat_list_1l (Feat) # flatting one level\n",
    "#    print \"\\nRetrieved list:\\n\", Feat\n",
    "\n",
    "    # Evaluating result...\n",
    "    # Filtering feature values from the definition list in global dictionary\n",
    "    def_list = [x[1] for x in Dict_defs['apple']]\n",
    "    \n",
    "    # Filtering feature values from obtained list\n",
    "    feat_val_list = [x[0] for x in Feat]\n",
    "    \n",
    "    print \"\\n# of features in definition:\", len(def_list)\n",
    "    # Percentage of successfully retrieved features\n",
    "    print \"\\nSuccessfully retrieved features:\",round(len(set(def_list).intersection(set(feat_val_list))) / float( len(def_list) )*100, 2) , \"%\" \n",
    "    \n",
    "    # List of distances (from retrieved vectors to original vectors in memory)\n",
    "    Dists_list = [x[1] for x in Feat]\n",
    "    # Average distance\n",
    "    print \"\\nAverage distance (from retrieved vector to stored ID vector):\", round( sum(Dists_list) / float(len(Dists_list)), 2)\n",
    "    # Max distance\n",
    "    print \"\\nMax distance (but smaller than threshold):\", max(Dists_list)\n",
    "    \n",
    "    # Hacer pruebas con el límite de 'compresión', es decir, probar con definiciones largas y ver si aun se recupera bien\n",
    "    # la información... puedo incluso hacer tablas de eso... mi umbral de 0.45 es adecuado??\n",
    "    \n",
    "    # Tampoco estaría mal hacer un programa que haga una matriz de distancias de todos los semantic pointers contra los demás...\n",
    "    \n",
    "    # Sería interesante probar la codificación de un grafo según gayler:  G = A * P(B) + A * P(C) + B * P(D)\n",
    "    # (si el vector es permutado es hijo, el no permutado es padre)\n",
    "    # ¿qué ventajas hay?, se ve que es más sencillo pero quien sabe que desventajas tenga....\n",
    "    \n",
    "Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
