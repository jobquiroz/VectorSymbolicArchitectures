{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing similarity measures\n",
    "\n",
    "In this notebook a comparison between experimental results on humans and different similarity metrics are compared. \n",
    "This version uses dictionaries to avoid running the program many times.\n",
    "\n",
    "# PENDING...\n",
    "\n",
    " - Normalizar todo.. \n",
    " - Respaldar en github...\n",
    " - Hacer comparaciones contra individuos especificos de la encuesta (mi respuesta y otras que parezcan coherentes..)\n",
    "   (PARA ESO debo de MARCAR las preguntas que eliminé...)\n",
    " - \"Normalizar\" datos, en vez de 1 - 6 pasar de 0 a 1... \n",
    " - Hacer un conjunto de prueba hecho por mi, de 20 parejas\n",
    " - Comenzar a añadir 'la otra forma' de codificar... hacer algunas pruebas básicas... \n",
    " - Viernes enseñar resultados a Barrón y preguntarle si añado lo de la otra forma de codificar... \n",
    "\n",
    "\n",
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from scipy.stats.stats import pearsonr   \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('wordnet_ic')\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import wordnet_ic\n",
    "\n",
    "exp_file = 'ExperimentalResults_2.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting pairs of concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['spoon', 'barrel'], ['shoes', 'bike'], ['spoon', 'truck'], ['chair', 'pen'], ['spoon', 'envelope'], ['shoes', 'whip'], ['spoon', 'box'], ['shoes', 'shield'], ['chair', 'book'], ['table', 'brush'], ['spoon', 'basket'], ['table', 'curtains'], ['spoon', 'ashtray'], ['table', 'barrel'], ['chair', 'car'], ['table', 'lamp'], ['carpet', 'scarf'], ['shoes', 'carpet'], ['bed', 'lamp'], ['bed', 'mink_(coat)'], ['table', 'knife'], ['chair', 'closet'], ['shoes', 'earmuffs'], ['chair', 'dresser'], ['table', 'spoon'], ['bed', 'curtains'], ['shoes', 'skirt'], ['chair', 'bookcase'], ['shoes', 'mink_(coat)'], ['table', 'bookcase'], ['bowl', 'bathtub'], ['bed', 'chair'], ['bed', 'closet'], ['spoon', 'colander'], ['shoes', 'belt'], ['bed', 'dresser'], ['table', 'sofa'], ['bed', 'table'], ['boots', 'belt'], ['pen', 'envelope'], ['bed', 'pajamas'], ['stove', 'pot'], ['table', 'bench'], ['bed', 'cushion'], ['shovel', 'machete'], ['table', 'chair'], ['spoon', 'tongs'], ['bed', 'sofa'], ['spoon', 'spatula'], ['spoon', 'plate'], ['bed', 'pillow'], ['knife', 'scissors'], ['shoes', 'socks'], ['table', 'desk'], ['cup', 'bottle'], ['skirt', 'trousers'], ['chair', 'sofa'], ['shoes', 'sandals'], ['chair', 'bench'], ['spoon', 'fork'], ['shoes', 'slippers'], ['chair', 'rocker'], ['spoon', 'ladle'], ['shoes', 'boots']]\n"
     ]
    }
   ],
   "source": [
    "def ListofPairs (number = None):\n",
    "    \"It obtains a list of pairs of concepts\"\n",
    "    df = pd.read_excel(exp_file)\n",
    "    if number:\n",
    "        string = 'Q' + str(number)    \n",
    "    else:\n",
    "        string = 'average'\n",
    "    # 1) List of concepts\n",
    "    ordered = df.sort_values(by=string)\n",
    "    c1 = map(str, list( ordered['concept 1'] ))\n",
    "    c2 = map(str, list( ordered['concept 2'] ))\n",
    "    L1 = map(list, zip(c1,c2))\n",
    "    # 2) Human similarity\n",
    "    ordered = df.sort_values(by=string)\n",
    "    L2 = map(lambda x: round(float(x), 3) / 10, list(ordered[string]))\n",
    "    \n",
    "    return L1, L2\n",
    "\n",
    "PConcepts, Hum_Sim = ListofPairs()\n",
    "print PConcepts\n",
    "#Hum_Sim = HumanSim()\n",
    "# Plotting\n",
    "#plt.plot(Hum_Sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HD Computing similarity\n",
    "\n",
    "### Initializing memory and encoding dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of initialization\n",
      "End of encoding\n"
     ]
    }
   ],
   "source": [
    "%run KB_HDComputing.ipynb\n",
    "\n",
    "# Initializing Memory\n",
    "Init_mem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing pairs of concepts in the HD binary space\n",
    "\n",
    "To make computations more efficient I created a dictionary where the similarity between a pair of concepts is stored. Everytime that a similarity is required the only thing to do is to consult this dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance vector\n",
    "HD_sim = []\n",
    "for cc in PConcepts:\n",
    "    HD_sim.append( HDvector.dist(Dict[cc[0]].getPointer(), Dict[cc[1]].getPointer()) )\n",
    "#Normalizing...\n",
    "HD_sim = map(lambda x: round(1. - x/float( max(HD_sim)) , 3), HD_sim)\n",
    "\n",
    "# Dictionary of distances\n",
    "Dict_HD = {}\n",
    "for key in range(len(HD_sim)):\n",
    "    Dict_HD[key] = HD_sim[key]\n",
    "\n",
    "# Plotting\n",
    "# plt.plot(HD_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## McRae similarity\n",
    "\n",
    "The following cells consult the similarity for each pair of concepts in the distance matrix provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def McRae_simi (pair_concepts):\n",
    "    \"Given a pair of concepts (in a list) it consults the similarity from the cos_matrix... file\"\n",
    "    try: \n",
    "        df = pd.read_excel(pathh + 'cos_matrix_brm_IFR.xlsx','1st_200')\n",
    "        return list(df.loc[df['CONCEPT'] == pair_concepts[0]][pair_concepts[1]])[0]\n",
    "    except:\n",
    "        try:\n",
    "            df = pd.read_excel(pathh + 'cos_matrix_brm_IFR.xlsx','2nd_200')\n",
    "            return list(df.loc[df['CONCEPT'] == pair_concepts[0]][pair_concepts[1]])[0]\n",
    "        except:\n",
    "            df = pd.read_excel(pathh + 'cos_matrix_brm_IFR.xlsx','last_141')\n",
    "            return list(df.loc[df['CONCEPT'] == pair_concepts[0]][pair_concepts[1]])[0]\n",
    "\n",
    "\n",
    "# Dictionary of distances (McRae)\n",
    "Dict_McRae = {}\n",
    "key = 0\n",
    "for cc in PConcepts:\n",
    "    Dict_McRae[key] = McRae_simi(cc)\n",
    "    key += 1\n",
    "\n",
    "#plt.plot( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NTLK Library functions\n",
    "\n",
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "\n",
    "def get_synset (concept):\n",
    "    \"Given a concept name (string) it returns its synset (string)\"\n",
    "    # Dataframe for excel document\n",
    "    df = pd.read_excel(pathh + 'CONCS_Synset_brm.xlsx') #../McRaedataset/CONCS_Synset_brm.xlsx')\n",
    "    row = df.loc[df['Concept'] == concept]\n",
    "    return str(list(row['Synset'] )[0])\n",
    "\n",
    "def similarity_fun ( similarity_metric, pair, corpus = None):\n",
    "    \"Given a similarity_metric function it returns a list of the num closest concepts to 'concept'\"\n",
    "    c_synset_1 = wn.synset( get_synset(pair[0]))\n",
    "    c_synset_2 = wn.synset( get_synset(pair[1]))\n",
    "    if corpus:\n",
    "        return round(similarity_metric(c_synset_1, c_synset_2, corpus), 3)\n",
    "    else:\n",
    "        return round(similarity_metric(c_synset_1, c_synset_2), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path similarity\n",
    "Dict_path = {}\n",
    "Dict_lch = {}\n",
    "Dict_wup = {}\n",
    "Dict_res = {}\n",
    "Dict_jcn = {}\n",
    "Dict_lin = {}\n",
    "\n",
    "key = 0\n",
    "for pair in PConcepts:\n",
    "    Dict_path[key] = similarity_fun(wn.path_similarity, pair)\n",
    "    Dict_lch[key] = similarity_fun(wn.lch_similarity, pair)\n",
    "    Dict_wup[key] = similarity_fun(wn.wup_similarity, pair)\n",
    "    Dict_res[key] = similarity_fun(wn.res_similarity, pair, brown_ic)\n",
    "    Dict_jcn[key] = similarity_fun(wn.jcn_similarity, pair, brown_ic)\n",
    "    Dict_lin[key] = similarity_fun(wn.lin_similarity, pair, brown_ic)\n",
    "    key += 1\n",
    "    \n",
    "#plt.plot(Path_sim) #plt.plot(LC_sim) #plt.plot(WUP_sim) #plt.plot(Res_sim) #plt.plot(JC_sim) #plt.plot(Lin_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations\n",
    "\n",
    "Using correlation to compare obtained similarity values from different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['jcn', 0.6180961294405283], ['HDC', 0.5010891380947233], ['res', 0.4521808448297293], ['path', 0.44434027075727306], ['average', 0.4425336317047693], ['lin', 0.40710257351959867], ['McRae', 0.39793935124858004], ['lch', 0.3849119836839587], ['wup', 0.33460876206376267]]\n"
     ]
    }
   ],
   "source": [
    "# 1) Obtain \"human list\", it can be the average responses or an specific one\n",
    "Hum_sim =  ListofPairs(11) #or Q + #1-30\n",
    "# 2) Obtain list of keys for previous list\n",
    "keys = map(lambda x: PConcepts.index(x), Hum_sim[0])\n",
    "\n",
    "# 3) Create a list of distances according to each metric by consulting the appropiate dictionary\n",
    "HD_sim = [Dict_HD[x] for x in keys]\n",
    "McRae_sim = [Dict_McRae[x] for x in keys]\n",
    "path_sim = [Dict_path[x] for x in keys]\n",
    "lch_sim = [Dict_lch[x] for x in keys]\n",
    "wup_sim = [Dict_wup[x] for x in keys]\n",
    "res_sim = [Dict_res[x] for x in keys]\n",
    "jcn_sim = [Dict_jcn[x] for x in keys]\n",
    "lin_sim = [Dict_lin[x] for x in keys]\n",
    "\n",
    "# 4) Calculate correlations\n",
    "correlations = [ ['HDC', pearsonr(Hum_sim[1], HD_sim)[0]], ['McRae', pearsonr(Hum_sim[1], McRae_sim)[0]],\n",
    "                 ['path', pearsonr(Hum_sim[1], path_sim)[0]], ['lch', pearsonr(Hum_sim[1], lch_sim)[0]],\n",
    "                 ['wup', pearsonr(Hum_sim[1], wup_sim)[0]], ['res', pearsonr(Hum_sim[1], res_sim)[0]],\n",
    "                 ['jcn', pearsonr(Hum_sim[1], jcn_sim)[0]], ['lin', pearsonr(Hum_sim[1], lin_sim)[0]]]\n",
    "\n",
    "# 5) Average correlation\n",
    "correlations.append(['average', np.mean([r[1] for r in correlations])])\n",
    "         \n",
    "correlations = sorted(correlations, key = lambda x: x[1], reverse = True)\n",
    "print correlations\n",
    "\n",
    "# Falta crear matriz de correlaciones... ver iPad... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2666666666666666\n"
     ]
    }
   ],
   "source": [
    "l = [[1,.8], [2,.5], [3,.3]]\n",
    "print np.mean([lambda ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
